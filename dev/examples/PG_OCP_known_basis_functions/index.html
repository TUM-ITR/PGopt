<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimal control with known basis functions ·  </title><meta name="title" content="Optimal control with known basis functions ·  "/><meta property="og:title" content="Optimal control with known basis functions ·  "/><meta property="twitter:title" content="Optimal control with known basis functions ·  "/><meta name="description" content="Documentation for  ."/><meta property="og:description" content="Documentation for  ."/><meta property="twitter:description" content="Documentation for  ."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="  logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../"> </a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../autocorrelation/">Autocorrelation</a></li><li class="is-active"><a class="tocitem" href>Optimal control with known basis functions</a><ul class="internal"><li><a class="tocitem" href="#Define-prior-and-parameters"><span>Define prior and parameters</span></a></li><li><a class="tocitem" href="#Generate-data"><span>Generate data</span></a></li><li><a class="tocitem" href="#Infer-model"><span>Infer model</span></a></li><li><a class="tocitem" href="#Define-and-solve-optimal-control-problem-using-Altro"><span>Define and solve optimal control problem using Altro</span></a></li><li><a class="tocitem" href="#Define-and-solve-optimal-control-problem-using-Ipopt"><span>Define and solve optimal control problem using Ipopt</span></a></li></ul></li><li><a class="tocitem" href="../PG_OCP_generic_basis_functions/">Optimal control with generic basis functions</a></li></ul></li><li><a class="tocitem" href="../../list_of_functions/">List of fuctions</a></li><li><a class="tocitem" href="../../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Optimal control with known basis functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimal control with known basis functions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TUM-ITR/PGopt" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/TUM-ITR/PGopt/blob/main/Julia/docs/src/examples/PG_OCP_known_basis_functions.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimal-control-with-known-basis-functions"><a class="docs-heading-anchor" href="#Optimal-control-with-known-basis-functions">Optimal control with known basis functions</a><a id="Optimal-control-with-known-basis-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-control-with-known-basis-functions" title="Permalink"></a></h1><p>This example reproduces the results of the optimal control approach with known basis functions (Figure 2) given in Section V-B of the <a href="../../reference/">paper</a>.</p><p><img src="../../assets/PG_OCP_known_basis_functions.svg" alt="autocorrelation"/></p><pre><code class="nohighlight hljs">### Support sub-sample found
Cardinality of the support sub-sample (s): 7
Max. constraint violation probability (1-epsilon): 10.22 %</code></pre><p>First, the algorithm and simulation parameters are defined, and training data is generated. Then, by calling the function <code>particle_Gibbs()</code>, samples are drawn from the posterior distribution using particle Gibbs sampling. These samples are then passed to the function <code>solve_PG_OCP_Altro_greedy_guarantees()</code> (or <code>solve_PG_OCP_Ipopt_greedy_guarantees()</code> in case IPOPT is used), which solves the scenario OCP using the solver Altro and inferres probabilistic constraint satisfaction guarantees by greedily removing constraints and solving the corresponding reduced OCP.</p><p>A Julia script that contains all the steps described in the following and exactly reproduces Figure 2 of the paper can be found at <code>PGopt/Julia/examples/PG_OCP_known_basis_functions_Altro.jl</code>. For the results in Table II of the paper, this script is repeated with seeds 1:100. The runtime of the script is about 2 hours on a standard laptop.</p><p>A similar example that utilizes the solver IPOPT can be found at <code>PGopt/Julia/examples/PG_OCP_known_basis_functions_Ipopt.jl</code>. Due to the different solver, the results differ slightly from the ones presented in the paper.</p><h2 id="Define-prior-and-parameters"><a class="docs-heading-anchor" href="#Define-prior-and-parameters">Define prior and parameters</a><a id="Define-prior-and-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Define-prior-and-parameters" title="Permalink"></a></h2><p>First, load packages and initialize.</p><pre><code class="language-julia hljs">using PGopt
using LinearAlgebra
using Random
using Distributions
using Printf
using Plots

# Specify seed (for reproducible results).
Random.seed!(82)

# Time PGS algorithm.
sampling_timer = time()</code></pre><p>Then, specify the parameters of the algorithm.</p><pre><code class="language-julia hljs"># Learning parameters
K = 200 # number of PG samples
k_d = 50 # number of samples to be skipped to decrease correlation (thinning)
K_b = 1000 # length of burn-in period
N = 30 # number of particles of the particle filter

# Number of states, etc.
n_x = 2 # number of states
n_u = 1 # number of control inputs
n_y = 1 # number of outputs</code></pre><p>Define the basis functions. The basis functions are assumed to be known in this example. Make sure that <span>$\phi(x, u)$</span> is defined in vectorized form, i.e., <code>phi(zeros(n_x, N), zeros(n_u, N))</code> should return a matrix of dimension <code>(n_phi, N)</code>.</p><pre><code class="language-julia hljs">n_phi = 5 # number of basis functions
phi(x, u) = [0.1 * x[1, :] 0.1 * x[2, :] u[1, :] 0.01 * cos.(3 * x[1, :]) .* x[2, :] 0.1 * sin.(2 * x[2, :]) .* u[1, :]]&#39; # basis functions</code></pre><p>Select the parameters of the inverse Wishart prior for <span>$Q$</span>.</p><pre><code class="language-julia hljs">ell_Q = 10 # degrees of freedom
Lambda_Q = 100 * I(n_x) # scale matrix</code></pre><p>Select the parameters of the matrix normal prior (with mean matrix <span>$0$</span>, right covariance matrix <span>$Q$</span> (see above), and left covariance matrix <span>$V$</span>) for <span>$A$</span>.</p><pre><code class="language-julia hljs">V = Diagonal(10 * ones(n_phi)) # left covariance matrix</code></pre><p>Provide an initial guess for the parameters.</p><pre><code class="language-julia hljs">Q_init = Lambda_Q # initial Q
A_init = zeros(n_x, n_phi) # initial A</code></pre><p>Choose the distribution of the initial state. Here, a normally distributed initial state is assumed.</p><pre><code class="language-julia hljs">x_init_mean = [2, 2] # mean
x_init_var = 1 * I # variance
x_init_dist = MvNormal(x_init_mean, x_init_var)</code></pre><p>Define the measurement model. It is assumed to be known (without loss of generality). Make sure that <span>$g(x, u)$</span> is defined in vectorized form, i.e., <code>g(zeros(n_x, N), zeros(n_u, N))</code> should return a matrix of dimension <code>(n_y, N)</code>.</p><pre><code class="language-julia hljs">g(x, u) = [1 0] * x # observation function
R = 0.1 # variance of zero-mean Gaussian measurement noise</code></pre><h2 id="Generate-data"><a class="docs-heading-anchor" href="#Generate-data">Generate data</a><a id="Generate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-data" title="Permalink"></a></h2><p>Generate training data.</p><pre><code class="language-julia hljs"># Parameters for data generation
T = 2000 # number of steps for training
T_test = 500 # number of steps used for testing (via forward simulation - see below)
T_all = T + T_test

# Unknown system
f_true(x, u) = [0.8 * x[1, :] - 0.5 * x[2, :] + 0.1 * cos.(3 * x[1, :]) .* x[2, :]; 0.4 * x[1, :] + 0.5 * x[2,:] + (ones(size(x, 2)) + 0.3 * sin.(2 * x[2, :])) .* u[1, :]] # true state transition function
Q_true = [0.03 -0.004; -0.004 0.01] # true process noise variance
mvn_v_true = MvNormal(zeros(n_x), Q_true) # true process noise distribution
g_true = g # true measurement function
R_true = R # true measurement noise variance
mvn_e_true = MvNormal(zeros(n_y), R_true) # true measurement noise distribution

# Input trajectory used to generate training and test data
mvn_u_training = Normal(0, 3) # training input distribution
u_training = rand(mvn_u_training, T) # training inputs
u_test = 3 * sin.(2 * pi * (1 / T_test) * (Array(1:T_test) .- 1)) # test inputs
u = reshape([u_training; u_test], 1, T_all) # training + test inputs

# Generate data by forward simulation.
x = Array{Float64}(undef, n_x, T_all + 1) # true latent state trajectory
x[:, 1] = rand(x_init_dist, 1) # random initial state
y = Array{Float64}(undef, n_y, T_all) # output trajectory (measured)
for t in 1:T_all
  x[:, t+1] = f_true(x[:, t], u[:, t]) + rand(mvn_v_true, 1)
  y[:, t] = g_true(x[:, t], u[:, t]) + rand(mvn_e_true, 1)
end

# Split data into training and test data.
u_training = u[:, 1:T]
x_training = x[:, 1:T+1]
y_training = y[:, 1:T]

u_test = u[:, T+1:end]
x_test = x[:, T+1:end]
y_test = y[:, T+1:end]</code></pre><h2 id="Infer-model"><a class="docs-heading-anchor" href="#Infer-model">Infer model</a><a id="Infer-model-1"></a><a class="docs-heading-anchor-permalink" href="#Infer-model" title="Permalink"></a></h2><p>Run the particle Gibbs sampler to jointly estimate the model parameters and the latent state trajectory.</p><pre><code class="language-julia hljs">PG_samples = particle_Gibbs(u_training, y_training, K, K_b, k_d, N, phi, Lambda_Q, ell_Q, Q_init, V, A_init, x_init_dist, g, R)

time_sampling = time() - sampling_timer</code></pre><h2 id="Define-and-solve-optimal-control-problem-using-Altro"><a class="docs-heading-anchor" href="#Define-and-solve-optimal-control-problem-using-Altro">Define and solve optimal control problem using Altro</a><a id="Define-and-solve-optimal-control-problem-using-Altro-1"></a><a class="docs-heading-anchor-permalink" href="#Define-and-solve-optimal-control-problem-using-Altro" title="Permalink"></a></h2><p>In the following, the optimal control problem is defined and solved using the solver Altro. An example using the solver IPOPT is given in the next section. With the Altro solver, problems of the following form can be solved</p><p><span>$\min \sum_{t=0}^{H} \frac{1}{2} u_t \operatorname{diag}(R_{\mathrm{cost}}) u_t$</span></p><p>subject to:</p><p class="math-container">\[\begin{aligned}
\forall k, \forall t \\
x_{t+1}^{[k]} &amp;= f_{\theta^{[k]}}(x_t^{[k]}, u_t) + v_t^{[k]} \\
x_{t, 1:n_y}^{[k]} &amp;\geq y_{\mathrm{min},\ t} - e_t^{[k]} \\
x_{t, 1:n_y}^{[k]} &amp;\leq y_{\mathrm{max},\ t} - e_t^{[k]} \\
u_t &amp;\geq u_{\mathrm{min},\ t} \\
u_t &amp;\leq u_{\mathrm{max},\ t}.
\end{aligned}\]</p><p>(Note that the output constraints imply the measurement function <span>$y_t^{[k]} = x_{t, 1:n_y}^{[k]}$</span>.)</p><pre><code class="language-julia hljs"># Horizon
H = 41

# Define constraints for u and y.
u_max = [5] # max control input
u_min = [-5] # min control input
y_max = reshape(fill(Inf, H), (1, H)) # max system output
y_min = reshape([-fill(Inf, 20); 2 * ones(6); -fill(Inf, 15)], (1, H)) # min system output

R_cost_diag = [2] # diagonal of R_cost</code></pre><p>Select the confidence parameter for the theoretical guarantees.</p><pre><code class="language-julia hljs">β = 0.01</code></pre><p>Solve the optimal control problem using the solver Altro and determine a support sub-sample with cardinality <span>$s$</span> via a greedy constraint removal.  Based on the cardinality <span>$s$</span>, a bound on the probability that the incurred cost exceeds the worst-case cost or that the constraints are violated when the input trajectory <span>$u_{0:H}$</span> is applied to the unknown system is calculated (i.e., <span>$1-\epsilon$</span> is determined).</p><pre><code class="language-julia hljs">u_opt, x_opt, y_opt, J_opt, s, epsilon_prob, epsilon_perc, time_first_solve, time_guarantees, num_failed_optimizations = solve_PG_OCP_Altro_greedy_guarantees(PG_samples, phi, R, H, u_min, u_max, y_min, y_max, R_cost_diag, β; K_pre_solve=20)</code></pre><p>Finally, apply the input trajectory to the actual system and plot the output trajectories.</p><pre><code class="language-julia hljs"># Apply input trajectory to the actual system.
y_sys = Array{Float64}(undef, n_y, H)
x_sys = Array{Float64}(undef, n_x, H)
x_sys[:, 1] = x_training[:, end]
u_sys = [u_opt 0]
for t in 1:H
  if t &gt;= 2
    x_sys[:, t] = f_true(x_sys[:, t-1], u_sys[:, t-1]) + rand(mvn_v_true, 1)
  end
  y_sys[:, t] = g_true(x_sys[:, t], u_sys[:, t]) + rand(mvn_e_true, 1)
end

# Plot predictions.
plot_predictions(y_opt, y_sys; plot_percentiles=false, y_min=y_min, y_max=y_max)</code></pre><h2 id="Define-and-solve-optimal-control-problem-using-Ipopt"><a class="docs-heading-anchor" href="#Define-and-solve-optimal-control-problem-using-Ipopt">Define and solve optimal control problem using Ipopt</a><a id="Define-and-solve-optimal-control-problem-using-Ipopt-1"></a><a class="docs-heading-anchor-permalink" href="#Define-and-solve-optimal-control-problem-using-Ipopt" title="Permalink"></a></h2><p>Besides the solver Altro, IPOPT can be used to solve the OCP. The solver IPOPT is more general than Altro, and this implementation allows arbitrary cost functions <span>$J_H(u_{1:H},x_{1:H},y_{1:H})$</span>, measurement functions <span>$y=g(x,u)$</span>, and constraints <span>$h(u_{1:H},x_{1:H},y_{1:H})$</span>.</p><p>First, load the necessary packages. </p><pre><code class="language-julia hljs">using JuMP
import HSL_jll # requires a proprietary license</code></pre><p>Then, set up the OCP.</p><pre><code class="language-julia hljs"># Set up OCP.
# Horizon
H = 41

# Define constraints for u.
u_max = repeat([5], 1, H) # max control input
u_min = repeat([-5], 1, H) # min control input
n_input_const = sum(isfinite.(u_min)) + sum(isfinite.(u_max))

# Define constraints for y.
y_max = reshape(fill(Inf, H), (1, H)) # max system output
y_min = reshape([-fill(Inf, 20); 2 * ones(6); -fill(Inf, 15)], (1, H)) # min system output
n_output_const = sum(isfinite.(y_min)) + sum(isfinite.(y_max))</code></pre><p>The following functions define the input and output constraints. The function <code>bounded_input()</code> returns the constraint vector <span>$h_1(u_{1:H})$</span> and the function <code>bounded_output()</code> returns the constraint vector <span>$h_2(u_{1:H},x_{1:H}^{[k]},y_{1:H}^{[k]})$</span>. Feasible solutions must satisfy <span>$h_1(u_{1:H}) \leq 0$</span> and <span>$h_2(u_{1:H},x_{1:H}^{[k]},y_{1:H}^{[k]}) \leq 0 \; \forall k$</span>. The functions should be callable with arrays of type <code>VariableRef</code> and <code>&lt;:Number</code>.</p><pre><code class="language-julia hljs">function bounded_input(u::Array{VariableRef})
  # Initialize constraint vector.
  h_u = Array{AffExpr}(undef, n_input_const)

  # Construct constraint vector - constraints are only considered if they are finite.
  i = 1
  for t in 1:H
    for n in 1:n_u
      if isfinite(u_min[n, t])
        h_u[i] = u_min[n, t] - u[n, t]
        i += 1
      end
      if isfinite(u_max[n, t])
        h_u[i] = u[n, t] - u_max[n, t]
        i += 1
      end
    end
  end
  return h_u
end

function bounded_input(u::Array{&lt;:Number})
  # Initialize constraint vector.
  h_u = Array{Float64}(undef, n_input_const)

  # Construct constraint vector - constraints are only considered if they are finite.
  i = 1
  for t in 1:H
    for n in 1:n_u
      if isfinite(u_min[n, t])
        h_u[i] = u_min[n, t] - u[n, t]
        i += 1
      end
      if isfinite(u_max[n, t])
        h_u[i] = u[n, t] - u_max[n, t]
        i += 1
      end
    end
  end
  return h_u
end

function bounded_output(u::Array{VariableRef}, x::Array{VariableRef}, y::Array{VariableRef})
  # Initialize constraint vector.
  h_scenario = Array{AffExpr}(undef, n_output_const)

  # Construct constraint vector - constraints are only considered if they are finite.
  i = 1
  for t in 1:H
    for n in 1:n_y
      if isfinite(y_min[n, t])
        h_scenario[i] = y_min[n, t] - y[n, t]
        i += 1
      end
      if isfinite(y_max[n, t])
        h_scenario[i] = y[n, t] - y_max[n, t]
        i += 1
      end
    end
  end
  return h_scenario
end

function bounded_output(u::Array{&lt;:Number}, x::Array{&lt;:Number}, y::Array{&lt;:Number})
  # Initialize constraint vector.
  h_scenario = Array{Float64}(undef, n_output_const)

  # Construct constraint vector - constraints are only considered if they are finite.
  i = 1
  for t in 1:H
    for n in 1:n_y
      if isfinite(y_min[n, t])
        h_scenario[i] = y_min[n, t] - y[n, t]
        i += 1
      end
      if isfinite(y_max[n, t])
        h_scenario[i] = y[n, t] - y_max[n, t]
        i += 1
      end
    end
  end
  return h_scenario
end</code></pre><p>Define the cost function. In this case the objective is <span>$\min \sum_{t=0}^{H} u_t^2$</span>.</p><pre><code class="language-julia hljs">function cost_function(u) 
  cost = sum(u.^2)
  return cost
end</code></pre><p>Then, set the solver&#39;s options. The option <code>&quot;linear_solver&quot; =&gt; &quot;ma57&quot;</code> requires the proprietary <a href="https://licences.stfc.ac.uk/product/libhsl">HSL Linear Solvers for Julia</a>.</p><pre><code class="language-julia hljs">Ipopt_options = Dict(&quot;max_iter&quot; =&gt; 10000, &quot;tol&quot; =&gt; 1e-8, &quot;hsllib&quot; =&gt; HSL_jll.libhsl_path, &quot;linear_solver&quot; =&gt; &quot;ma57&quot;)</code></pre><p>Select the confidence parameter for the theoretical guarantees.</p><pre><code class="language-julia hljs">β = 0.01</code></pre><p>Solve the optimal control problem using the solver IPOPT and determine a support sub-sample with cardinality <span>$s$</span> via a greedy constraint removal.  Based on the cardinality <span>$s$</span>, a bound on the probability that the incurred cost exceeds the worst-case cost or that the constraints are violated when the input trajectory <span>$u_{0:H}$</span> is applied to the unknown system is calculated (i.e., <span>$1-\epsilon$</span> is determined). Since the cost function depends only on the control inputs <span>$u_{0:H}$</span>, the optional argument <code>J_u</code> is set to <code>true</code>.</p><pre><code class="language-julia hljs">u_opt, x_opt, y_opt, J_opt, s, epsilon_prob, epsilon_perc, time_first_solve, time_guarantees, num_failed_optimizations = solve_PG_OCP_Ipopt_greedy_guarantees(PG_samples, phi, g, R, H, cost_function, bounded_output, bounded_input, β; J_u=true, K_pre_solve=5, solver_opts=copy(Ipopt_options))</code></pre><p>Finally, apply the input trajectory to the actual system and plot the output trajectories.</p><pre><code class="language-julia hljs"># Apply input trajectory to the actual system.
y_sys = Array{Float64}(undef, n_y, H)
x_sys = Array{Float64}(undef, n_x, H)
x_sys[:, 1] = x_training[:, end]
u_sys = [u_opt 0]
for t in 1:H
  if t &gt;= 2
    x_sys[:, t] = f_true(x_sys[:, t-1], u_sys[:, t-1]) + rand(mvn_v_true, 1)
  end
  y_sys[:, t] = g_true(x_sys[:, t], u_sys[:, t]) + rand(mvn_e_true, 1)
end

# Plot predictions.
plot_predictions(y_opt, y_sys; plot_percentiles=false, y_min=y_min, y_max=y_max)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../autocorrelation/">« Autocorrelation</a><a class="docs-footer-nextpage" href="../PG_OCP_generic_basis_functions/">Optimal control with generic basis functions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Thursday 19 December 2024 12:08">Thursday 19 December 2024</span>. Using Julia version 1.10.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
